# Kafkanauts
### Requirements:
We represent one of two teams of Scala developers. Both teams will create data, send it to their other team, and analyze what they receive.
This requires us to:
- Produce data representing orders on an E-Commerce application by using Kafka
  - This data will be created semi-randomly based on patterns and statistics
  - Can be intentionally corrupted data
  - Will be generated by a fixed pattern that won't suddenly change
- Ingest the other teams data as a Topic
  - Gracefully handle data input, being hardened against errors and corrupt data
  - Read data into DataFrames/DataSets, applying a given Schema to the data
  - Collect data and apply needed manipulations and aggregations to understand what algorithms created it
  - Display findings as visualizations in Zeppelin 
  - Output Topics in a Console consumer (CLI)


### Presentations
- Bring a simple slide deck providing an overview of your results. You should present your results, a high level overview of the process used to achieve those results, and any assumptions and simplifications you made on the way to those results.
- I may ask you to run an analysis on the day of the presentation, so be prepared to do so.
- We'll have 20 minutes per group, so make sure your presentation can be covered in that time, focusing on the parts of your analysis you find most interesting.
- Include a link to your github repository at the end of your slides


### Technologies
- Apache Spark
- Spark SQL
- YARN
- HDFS and/or S3
- Scala 2.12.10
- Kafka 2.8.1
- Git + GitHub
- Zeppelin


### Due Date
- Presentations will take place on Monday, 2/10
